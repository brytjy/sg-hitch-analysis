{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import calendar\n",
    "from collections import Counter\n",
    "import requests\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# WEB CRAWL\n",
    "import urllib\n",
    "import random\n",
    "import datetime as dt\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date(date):\n",
    "    # Remove special characters\n",
    "    date = re.sub('[^a-z0-9]', \" \", date)\n",
    "    try:\n",
    "        # ASSUMING dd MMM\n",
    "        # Extract day\n",
    "        day_start = re.search('^\\d+', date).start()\n",
    "        day_end = re.search('^\\d+', date).end()\n",
    "        day = date[day_start:day_end]\n",
    "        if len(day) == 1:\n",
    "            day = \"0\"+day\n",
    "        # Extract month\n",
    "        date_wo_day = date[day_end:].strip()\n",
    "        month_start = re.search('^\\w+', date_wo_day).start()\n",
    "        month_end = re.search('^\\w+', date_wo_day).end()\n",
    "        month = date_wo_day[month_start:month_end]\n",
    "        if \"jan\" in str(month):\n",
    "            month = \"01\"\n",
    "        if \"feb\" in str(month):\n",
    "            month = \"02\"\n",
    "        if \"mar\" in str(month):\n",
    "            month = \"03\"\n",
    "        if \"apr\" in str(month):\n",
    "            month = \"04\"\n",
    "        if \"may\" in str(month):\n",
    "            month = \"05\"\n",
    "        if \"jun\" in str(month):\n",
    "            month = \"06\"\n",
    "        if \"jul\" in str(month):\n",
    "            month = \"07\"\n",
    "        if \"aug\" in str(month):\n",
    "            month = \"08\"\n",
    "        if \"sep\" in str(month):\n",
    "            month = \"09\"\n",
    "        if \"oct\" in str(month):\n",
    "            month = \"10\"\n",
    "        if \"nov\" in str(month):\n",
    "            month = \"11\"\n",
    "        if \"dec\" in str(month):\n",
    "            month = \"12\"\n",
    "\n",
    "        full_date = day+\".\"+month+\".2019\"\n",
    "        if len(full_date) == 10:\n",
    "            return datetime.strptime(full_date, '%d.%m.%Y').date()\n",
    "        else:\n",
    "            return \"nil\"\n",
    "    except:\n",
    "        return \"nil\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_time(time, post_time):\n",
    "    return_time = \"nil\"\n",
    "    time_original = str(re.sub(r'[.:]', '', time)).strip()\n",
    "    time_original = str(re.sub(r'^([a-zA-Z]+ ){1,}', '', time_original)).strip()\n",
    "    time_original = str(re.sub(r'\\d+\\-', '', time_original)).strip()\n",
    "    \n",
    "    # ASSUME NUM PM\n",
    "    if bool(re.search(r'^\\d+ ?pm', time_original)):\n",
    "        time = time_original.replace(\"pm\", \"\").strip()\n",
    "        time = str(time)\n",
    "        # If 1,2,3,4,5,6,7,8,9\n",
    "        if len(str(time)) == 1:\n",
    "            time = int(time)\n",
    "            if time == 1:\n",
    "                return_time = \"13:00\"\n",
    "            if time == 2:\n",
    "                return_time = \"14:00\"\n",
    "            if time == 3:\n",
    "                return_time = \"15:00\"\n",
    "            if time == 4:\n",
    "                return_time = \"16:00\"\n",
    "            if time == 5:\n",
    "                return_time = \"17:00\"\n",
    "            if time == 6:\n",
    "                return_time = \"18:00\"\n",
    "            if time == 7:\n",
    "                return_time = \"19:00\"\n",
    "            if time == 8:\n",
    "                return_time = \"20:00\"\n",
    "            if time == 9:\n",
    "                return_time = \"21:00\"\n",
    "        # If 10,11,12\n",
    "        if len(str(time)) == 2:\n",
    "            time = int(time)\n",
    "            if time == 10:\n",
    "                return_time = \"22:00\"\n",
    "            if time == 11:\n",
    "                return_time = \"23:00\"\n",
    "            if time == 12:\n",
    "                return_time = \"12:00\"\n",
    "        # If single hour (eg. 1) and minutes (eg. 15)\n",
    "        if len(str(time)) == 3:\n",
    "            hour = int(time[0])\n",
    "            if hour == 1:\n",
    "                return_time = \"13:\"+time[1:]\n",
    "            if hour == 2:\n",
    "                return_time = \"14:\"+time[1:]\n",
    "            if hour == 3:\n",
    "                return_time = \"15:\"+time[1:]\n",
    "            if hour == 4:\n",
    "                return_time = \"16:\"+time[1:]\n",
    "            if hour == 5:\n",
    "                return_time = \"17:\"+time[1:]\n",
    "            if hour == 6:\n",
    "                return_time = \"18:\"+time[1:]\n",
    "            if hour == 7:\n",
    "                return_time = \"19:\"+time[1:]\n",
    "            if hour == 8:\n",
    "                return_time = \"20:\"+time[1:]\n",
    "            if hour == 9:\n",
    "                return_time = \"21:\"+time[1:]\n",
    "        # If double hour (eg. 11) and minutes (eg. 30)\n",
    "        if len(str(time)) == 4:\n",
    "            hour = int(time[0:2])\n",
    "            if hour == 10:\n",
    "                return_time = \"22:\"+time[2:]\n",
    "            if hour == 11:\n",
    "                return_time = \"23:\"+time[2:]\n",
    "            if hour == 12:\n",
    "                return_time = \"12:\"+time[2:]\n",
    "    \n",
    "    # ASSUME NUM AM\n",
    "    if bool(re.search(r'^\\d+ ?am', time_original)):\n",
    "        time = time_original.replace(\"am\", \"\").strip()\n",
    "        time = str(time)\n",
    "        # If 1,2,3,4,5,6,7,8,9\n",
    "        if len(str(time)) == 1:\n",
    "            time = int(time)\n",
    "            if time == 1:\n",
    "                return_time = \"01:00\"\n",
    "            if time == 2:\n",
    "                return_time = \"02:00\"\n",
    "            if time == 3:\n",
    "                return_time = \"03:00\"\n",
    "            if time == 4:\n",
    "                return_time = \"04:00\"\n",
    "            if time == 5:\n",
    "                return_time = \"05:00\"\n",
    "            if time == 6:\n",
    "                return_time = \"06:00\"\n",
    "            if time == 7:\n",
    "                return_time = \"07:00\"\n",
    "            if time == 8:\n",
    "                return_time = \"08:00\"\n",
    "            if time == 9:\n",
    "                return_time = \"09:00\"\n",
    "        # If 10,11,12\n",
    "        if len(str(time)) == 2:\n",
    "            time = int(time)\n",
    "            if time == 10:\n",
    "                return_time = \"10:00\"\n",
    "            if time == 11:\n",
    "                return_time = \"11:00\"\n",
    "            if time == 12:\n",
    "                return_time = \"00:00\"\n",
    "        # If single hour (eg. 1) and minutes (eg. 15)\n",
    "        if len(str(time)) == 3:\n",
    "            hour = int(time[0])\n",
    "            if hour == 1:\n",
    "                return_time = \"01:\"+time[1:]\n",
    "            if hour == 2:\n",
    "                return_time = \"02:\"+time[1:]\n",
    "            if hour == 3:\n",
    "                return_time = \"03:\"+time[1:]\n",
    "            if hour == 4:\n",
    "                return_time = \"04:\"+time[1:]\n",
    "            if hour == 5:\n",
    "                return_time = \"05:\"+time[1:]\n",
    "            if hour == 6:\n",
    "                return_time = \"06:\"+time[1:]\n",
    "            if hour == 7:\n",
    "                return_time = \"07:\"+time[1:]\n",
    "            if hour == 8:\n",
    "                return_time = \"08:\"+time[1:]\n",
    "            if hour == 9:\n",
    "                return_time = \"09:\"+time[1:]\n",
    "        # If double hour (eg. 11) and minutes (eg. 30)\n",
    "        if len(str(time)) == 4:\n",
    "            hour = int(time[0:2])\n",
    "            if hour == 10:\n",
    "                return_time = \"10:\"+time[2:]\n",
    "            if hour == 11:\n",
    "                return_time = \"11:\"+time[2:]\n",
    "            if hour == 12:\n",
    "                return_time = \"00:\"+time[2:]\n",
    "    \n",
    "    # ASSUME NO PM OR AM\n",
    "    if bool(re.search(r'^\\d+$', time_original)):\n",
    "        time = str(time_original).strip()\n",
    "        # If single digit\n",
    "        if len(time) == 1:\n",
    "            time = int(time)\n",
    "            post_hour = post_time[:2]\n",
    "            if int(post_hour) >= 12:\n",
    "                if time == 1:\n",
    "                    return_time = \"13:00\"\n",
    "                if time == 2:\n",
    "                    return_time = \"14:00\"\n",
    "                if time == 3:\n",
    "                    return_time = \"15:00\"\n",
    "                if time == 4:\n",
    "                    return_time = \"16:00\"\n",
    "                if time == 5:\n",
    "                    return_time = \"17:00\"\n",
    "                if time == 6:\n",
    "                    return_time = \"18:00\"\n",
    "                if time == 7:\n",
    "                    return_time = \"19:00\"\n",
    "                if time == 8:\n",
    "                    return_time = \"20:00\"\n",
    "                if time == 9:\n",
    "                    return_time = \"21:00\"\n",
    "            else:\n",
    "                if time == 1:\n",
    "                    return_time = \"01:00\"\n",
    "                if time == 2:\n",
    "                    return_time = \"02:00\"\n",
    "                if time == 3:\n",
    "                    return_time = \"03:00\"\n",
    "                if time == 4:\n",
    "                    return_time = \"04:00\"\n",
    "                if time == 5:\n",
    "                    return_time = \"05:00\"\n",
    "                if time == 6:\n",
    "                    return_time = \"06:00\"\n",
    "                if time == 7:\n",
    "                    return_time = \"07:00\"\n",
    "                if time == 8:\n",
    "                    return_time = \"08:00\"\n",
    "                if time == 9:\n",
    "                    return_time = \"09:00\"\n",
    "        # If double digits\n",
    "        if len(str(time)) == 2:\n",
    "            time = int(time)\n",
    "            post_hour = post_time[:2]\n",
    "            if int(post_hour) >= 12:\n",
    "                if time == 10:\n",
    "                    return_time = \"22:00\"\n",
    "                if time == 11:\n",
    "                    return_time = \"23:00\"\n",
    "                if time == 12:\n",
    "                    return_time = \"12:00\"\n",
    "            else:\n",
    "                if time == 10:\n",
    "                    return_time = \"10:00\"\n",
    "                if time == 11:\n",
    "                    return_time = \"11:00\"\n",
    "                if time == 12:\n",
    "                    return_time = \"00:00\"    \n",
    "        # If three digtis\n",
    "        if len(str(time)) == 3:\n",
    "            hour = int(str(time)[0])\n",
    "            post_hour = post_time[:2]\n",
    "            if int(post_hour) >= 12:\n",
    "                if hour == 1:\n",
    "                    return_time = \"13:\"+time[1:]\n",
    "                if hour == 2:\n",
    "                    return_time = \"14:\"+time[1:]\n",
    "                if hour == 3:\n",
    "                    return_time = \"15:\"+time[1:]\n",
    "                if hour == 4:\n",
    "                    return_time = \"16:\"+time[1:]\n",
    "                if hour == 5:\n",
    "                    return_time = \"17:\"+time[1:]\n",
    "                if hour == 6:\n",
    "                    return_time = \"18:\"+time[1:]\n",
    "                if hour == 7:\n",
    "                    return_time = \"19:\"+time[1:]\n",
    "                if hour == 8:\n",
    "                    return_time = \"20:\"+time[1:]\n",
    "                if hour == 9:\n",
    "                    return_time = \"21:\"+time[1:]\n",
    "            else:\n",
    "                if hour == 1:\n",
    "                    return_time = \"01:\"+time[1:]\n",
    "                if hour == 2:\n",
    "                    return_time = \"02:\"+time[1:]\n",
    "                if hour == 3:\n",
    "                    return_time = \"03:\"+time[1:]\n",
    "                if hour == 4:\n",
    "                    return_time = \"04:\"+time[1:]\n",
    "                if hour == 5:\n",
    "                    return_time = \"05:\"+time[1:]\n",
    "                if hour == 6:\n",
    "                    return_time = \"06:\"+time[1:]\n",
    "                if hour == 7:\n",
    "                    return_time = \"07:\"+time[1:]\n",
    "                if hour == 8:\n",
    "                    return_time = \"08:\"+time[1:]\n",
    "                if hour == 9:\n",
    "                    return_time = \"09:\"+time[1:]\n",
    "        # If four digtis\n",
    "        if len(str(time)) == 4:\n",
    "            hour = int(str(time)[0:2])\n",
    "            post_hour = post_time[:2]\n",
    "            if int(post_hour) >= 12:\n",
    "                if hour >= 12:\n",
    "                    return_time = str(hour)+\":\"+str(time)[2:]\n",
    "                if hour == 10:\n",
    "                    return_time = \"22:\"+time[2:]\n",
    "                if hour == 11:\n",
    "                    return_time = \"23:\"+time[2:]\n",
    "                if hour == 0:\n",
    "                    return_time = \"00:\"+time[2:]\n",
    "            else:\n",
    "                if hour <= 12:\n",
    "                    if len(str(hour)) == 1:\n",
    "                        return_time = \"0\"+str(hour)+\":\"+str(time)[2:]\n",
    "                    else:\n",
    "                        return_time = str(hour)+\":\"+str(time)[2:]\n",
    "                if hour == 0:\n",
    "                    return_time = \"00:\"+time[2:]\n",
    "                if hour == 10:\n",
    "                    return_time = \"10:\"+time[2:]\n",
    "                if hour == 11:\n",
    "                    return_time = \"11:\"+time[2:]\n",
    "                if hour == 12:\n",
    "                    return_time = \"00:\"+time[2:]\n",
    "        \n",
    "    return return_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files:  257\n",
      "['./telegram_chat_export_beginning_19sep\\\\messages.html', './telegram_chat_export_beginning_19sep\\\\messages10.html', './telegram_chat_export_beginning_19sep\\\\messages100.html', './telegram_chat_export_beginning_19sep\\\\messages101.html', './telegram_chat_export_beginning_19sep\\\\messages102.html', './telegram_chat_export_beginning_19sep\\\\messages103.html', './telegram_chat_export_beginning_19sep\\\\messages104.html', './telegram_chat_export_beginning_19sep\\\\messages105.html', './telegram_chat_export_beginning_19sep\\\\messages106.html', './telegram_chat_export_beginning_19sep\\\\messages107.html']\n",
      "\n",
      "Number of files:  160\n",
      "['./telegram_chat_export_13oct_10dec\\\\messages.html', './telegram_chat_export_13oct_10dec\\\\messages10.html', './telegram_chat_export_13oct_10dec\\\\messages100.html', './telegram_chat_export_13oct_10dec\\\\messages101.html', './telegram_chat_export_13oct_10dec\\\\messages102.html', './telegram_chat_export_13oct_10dec\\\\messages103.html', './telegram_chat_export_13oct_10dec\\\\messages104.html', './telegram_chat_export_13oct_10dec\\\\messages105.html', './telegram_chat_export_13oct_10dec\\\\messages106.html', './telegram_chat_export_13oct_10dec\\\\messages107.html']\n"
     ]
    }
   ],
   "source": [
    "html_files_old = glob.glob(\"./telegram_chat_export_beginning_19sep/*.html\")\n",
    "print(\"Number of files: \", len(html_files_old))\n",
    "print(html_files_old[:10])\n",
    "print()\n",
    "\n",
    "html_files_new = glob.glob(\"./telegram_chat_export_13oct_10dec/*.html\")\n",
    "print(\"Number of files: \", len(html_files_new))\n",
    "print(html_files_new[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total html files:  417\n"
     ]
    }
   ],
   "source": [
    "html_files = [*html_files_old, *html_files_new]\n",
    "print(\"Total html files: \", len(html_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Data from Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 417/417 [05:49<00:00,  1.09it/s]\n"
     ]
    }
   ],
   "source": [
    "messages_list = []\n",
    "total_messages = 0\n",
    "\n",
    "for file in tqdm(html_files):    \n",
    "    f = open(file, \"r\", encoding='utf-8')\n",
    "    chat = f.read()\n",
    "    soup = BeautifulSoup(chat)\n",
    "    messages = soup.findAll(\"div\", {\"class\": \"message default clearfix\"})\n",
    "    total_messages += len(messages)\n",
    "\n",
    "    for message in messages:\n",
    "        # Get user\n",
    "        user = message.find(\"div\", {\"class\": \"from_name\"}).text.replace(\"\\n\", \"\").strip()\n",
    "        #print(user)\n",
    "        # Get post date and time\n",
    "        post_datetime = message.find(\"div\", {\"class\": \"pull_right date details\"}).get(\"title\")\n",
    "        post_date = post_datetime.split(\" \")[0]\n",
    "        post_time = post_datetime.split(\" \")[1]\n",
    "        #print(post_date)\n",
    "        #print(post_time)\n",
    "        # GET MESSAGE\n",
    "        raw_message = message.find(\"div\", {\"class\": \"text\"})\n",
    "        # Extract text from message\n",
    "        raw_message = str(raw_message).replace(\"</div>\", \"\").replace('<div class=\"text\">', \"\").replace(\"<strong>\", \"\").replace(\"</strong>\", \"\").replace(\"<u>\", \"\").replace(\"</u>\", \"\").strip().lower()\n",
    "        # Tokenize text\n",
    "        raw_message_tokens = re.sub(r'(<br/> ?){2,}', '<br/>', raw_message).split(\"<br/>\")\n",
    "\n",
    "        # Variable flag for actual ride request\n",
    "        is_request = False\n",
    "        # Get user type\n",
    "        if(bool(re.search(r'hitchers? looking', raw_message_tokens[0]))):\n",
    "            user_type = \"hitcher\"\n",
    "            is_request = True\n",
    "        elif(bool(re.search(r'driver? looking', raw_message_tokens[0]))):\n",
    "            user_type = \"driver\"\n",
    "            is_request = True\n",
    "        else:\n",
    "            user_type = \"nil\"\n",
    "\n",
    "        # PROCESS MESSAGE CONTENT IF IT IS ACTUALLY A REQUEST\n",
    "        if(is_request):\n",
    "            # Blank place holder\n",
    "            pick_up = \"nil\"\n",
    "            drop_off = \"nil\"\n",
    "            request_date = \"nil\"\n",
    "            request_time = \"nil\"\n",
    "            number_of_pax = \"nil\"\n",
    "            request_date_normalised = \"nil\"\n",
    "            request_time_normalised = \"nil\"\n",
    "            day = \"nil\"\n",
    "            # ------------------\n",
    "\n",
    "            # Extract pick up location assuming it is always the second token\n",
    "            try:\n",
    "                pick_up_tokens = str(raw_message_tokens[1]).split(\":\")\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                if \"pick\" in pick_up_tokens[0]:\n",
    "                    pick_up = pick_up_tokens[1].strip()\n",
    "            except:\n",
    "                pick_up_tokens = str(raw_message_tokens[1]).split(\" \")\n",
    "                if \"pick\" in pick_up_tokens[0]:\n",
    "                    pick_up = \" \".join(pick_up_tokens[1:])\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "            # Extract drop off location assuming it is always the third token\n",
    "            try:\n",
    "                drop_off_tokens = str(raw_message_tokens[2]).split(\":\")\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                if \"drop\" in drop_off_tokens[0]:\n",
    "                    drop_off = drop_off_tokens[1].strip()\n",
    "            except:\n",
    "                drop_off_tokens = str(raw_message_tokens[2]).split(\" \")\n",
    "                if \"drop\" in drop_off_tokens[0]:\n",
    "                    drop_off = \" \".join(drop_off_tokens[1:])\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "            # Extract date assuming it is always the fourth token\n",
    "            try:\n",
    "                date_tokens = str(raw_message_tokens[3]).split(\":\")\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                if \"date\" in date_tokens[0]:\n",
    "                    request_date = date_tokens[1].strip()\n",
    "            except:\n",
    "                date_tokens = str(raw_message_tokens[3]).split(\" \")\n",
    "                if \"date\" in date_tokens[0]:\n",
    "                    request_date = \" \".join(date_tokens[1:])\n",
    "                else:\n",
    "                    pass\n",
    "            if \"today\" in request_date or \"tdy\" in request_date:\n",
    "                request_date = datetime.strptime(post_date, '%d.%m.%Y').date()\n",
    "            elif \"tmr\" in request_date or \"tomorrow\" in request_date:\n",
    "                today_date = datetime.strptime(post_date, '%d.%m.%Y').date()\n",
    "                tomorrow_date = today_date + timedelta(days=1)\n",
    "                request_date = tomorrow_date\n",
    "            elif request_date == \"nil\":\n",
    "                pass\n",
    "            else:\n",
    "                request_date = convert_date(request_date)\n",
    "            \n",
    "            # Extract time assuming it is always the fifth token\n",
    "            try:\n",
    "                time_raw = str(raw_message_tokens[4])\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                time = time_raw.replace(\"time:\", \"\").replace(\"time :\", \"\").strip()\n",
    "                time = re.sub(r'[^a-z0-9.-:]', '', time).strip()\n",
    "                if \"now\" in time:\n",
    "                    request_time = post_time[:5]\n",
    "                else:\n",
    "                    request_time = convert_time(str(time), post_time)\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "            # Extract number of pax assuming it is always the sixth token\n",
    "            try:\n",
    "                if \"pax\" in raw_message_tokens[5]:\n",
    "                    raw_pax = str(raw_message_tokens[5]).replace(\"pax:\", \"\").replace(\"pax\", \"\").replace(\"pax :\", \"\").replace(\"pax : \", \"\").strip()\n",
    "                    raw_pax = raw_pax.replace(\":\", \"\").strip()\n",
    "                    raw_pax = re.sub(r'\\(.*\\)', '', raw_pax)\n",
    "                    raw_pax = re.sub(r'[^a-z0-9- ]', '', raw_pax)\n",
    "                    raw_pax = raw_pax.strip()\n",
    "                    if len(raw_pax) == 1:\n",
    "                        number_of_pax = raw_pax\n",
    "                    elif len(raw_pax) == 3:\n",
    "                        number_of_pax = raw_pax\n",
    "                    else:\n",
    "                        if bool(re.search(r'^\\d+ - \\d+$', raw_pax)):\n",
    "                            number_of_pax = raw_pax.replace(\" \", \"\")\n",
    "                        if bool(re.search(r'^\\d+ to \\d+$', raw_pax)):\n",
    "                            number_of_pax = raw_pax.replace(\"to\", \"-\")\n",
    "                            number_of_pax = number_of_pax.replace(\" \", \"\")\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # If request_date and time is \"nil\" format of message might be wrong\n",
    "            if request_date == \"nil\" or request_time == \"nil\":\n",
    "                # Extract time again\n",
    "                try:\n",
    "                    time_raw = re.search(r'time\\:.*\\<br\\/\\>', raw_message).group()\n",
    "                    time = time_raw.split(\"<br/>\")[0]\n",
    "                    time = time.replace(\"time:\", \"\").strip()  \n",
    "                    if \"now\" in time:\n",
    "                        request_time = post_time[:5]\n",
    "                    else:\n",
    "                        request_time = convert_time(str(time), post_time)\n",
    "                except:\n",
    "                    pass\n",
    "                # Extract date again\n",
    "                try:\n",
    "                    date_raw = re.search(r'date\\:.*\\<br\\/\\>', raw_message).group()\n",
    "                    request_date = date_raw.split(\"<br/>\")[0]\n",
    "                    request_date = date.replace(\"date:\", \"\").strip()\n",
    "                    if \"today\" in request_date or \"tdy\" in request_date:\n",
    "                        request_date = datetime.strptime(post_date, '%d.%m.%Y').date()\n",
    "                    elif \"tmr\" in request_date or \"tomorrow\" in request_date:\n",
    "                        today_date = datetime.strptime(post_date, '%d.%m.%Y').date()\n",
    "                        tomorrow_date = today_date + timedelta(days=1)\n",
    "                        request_date = tomorrow_date\n",
    "                    else:\n",
    "                        request_date = convert_date(request_date)\n",
    "                except:\n",
    "                    if request_time != \"nil\":\n",
    "                        request_date = datetime.strptime(post_date, '%d.%m.%Y').date()\n",
    "                # Extract pax again\n",
    "                try:\n",
    "                    if bool(re.search(r'pax:.*\\<br\\/\\>', raw_message)):\n",
    "                        raw_pax = re.search(r'pax:.*\\<br\\/\\>', lol).group()\n",
    "                        raw_pax = raw_pax.split(\"<br/>\")[0]\n",
    "                        raw_pax = raw_pax.replace(\"pax:\", \"\").strip()\n",
    "                    if bool(re.search(r'pax:.*$', lol)):\n",
    "                        raw_pax = re.search(r'pax:.*$', lol).group()\n",
    "                        raw_pax = raw_pax.replace(\"pax:\", \"\").strip()\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            #--------------------NORMALISE DATA---------------------\n",
    "            \n",
    "            # Normalise date and time\n",
    "            try:\n",
    "                date_time = datetime.strptime(str(request_date)+\" \"+request_time, '%Y-%m-%d %H:%M')\n",
    "                approx = round(date_time.minute/30.0) * 30\n",
    "                date_time = date_time.replace(minute=0)\n",
    "                date_time += timedelta(seconds=approx*60)\n",
    "                request_date_normalised = date_time.date()\n",
    "                request_time_normalised = date_time.strftime('%H:%M')\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Add day to data eg. dd-mm-yyyy = wed\n",
    "            try:\n",
    "                my_date = datetime.strptime(str(request_date_normalised), '%Y-%m-%d')\n",
    "                day = calendar.day_name[my_date.weekday()].lower()\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Store structured message into dictionary\n",
    "            message_data = {\n",
    "                'user' : user,\n",
    "                'post_date' : post_date,\n",
    "                'post_time' : post_time,\n",
    "                'raw_message' : raw_message,\n",
    "                'user_type' : user_type,\n",
    "                'pick_up' : pick_up,\n",
    "                'drop_off' : drop_off,\n",
    "                'request_date' : request_date,\n",
    "                'request_date_normalised' : request_date_normalised,\n",
    "                'request_time' : request_time,\n",
    "                'request_time_normalised' : request_time_normalised,\n",
    "                'day' : day,\n",
    "                'number_of_pax' : number_of_pax\n",
    "            }\n",
    "            messages_list.append(message_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of messages: \t\t 376598\n",
      "Total number of actual messages: \t 360464\n",
      "\n",
      "Percentage of actual messages: \t 95.72 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of messages: \\t\\t\", total_messages)\n",
    "print(\"Total number of actual messages: \\t\", len(messages_list))\n",
    "print()\n",
    "print(\"Percentage of actual messages: \\t\", round((len(messages_list)/total_messages)*100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Data to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(messages_list)\n",
    "data.head()\n",
    "data.to_csv(\"./data/sg_hitch_data_raw_updated.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out Corrupted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 18292 corrupted request time\n",
      "Removed 0 corrupted request date\n",
      "Removed 318 corrupted pick up\n",
      "Removed 2341 corrupted drop off\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data/sg_hitch_data_raw_updated.csv\", index_col=0)\n",
    "\n",
    "# Filter out corrupted request time\n",
    "clean_data_rt = data[data.request_time_normalised != \"nil\"]\n",
    "print(\"Removed\", len(data)-len(clean_data_rt), \"corrupted request time\")\n",
    "# Filter out corrupted request date\n",
    "clean_data_rd = clean_data_rt[clean_data_rt.request_date_normalised != \"nil\"]\n",
    "print(\"Removed\", len(clean_data_rt)-len(clean_data_rd), \"corrupted request date\")\n",
    "# Filter out corrupted pick up\n",
    "clean_data_pu = clean_data_rd[clean_data_rd.pick_up != \"nil\"]\n",
    "print(\"Removed\", len(clean_data_rd)-len(clean_data_pu), \"corrupted pick up\")\n",
    "# Filter out corrupted drop off\n",
    "clean_data_do = clean_data_pu[clean_data_pu.drop_off != \"nil\"]\n",
    "print(\"Removed\", len(clean_data_pu)-len(clean_data_do), \"corrupted drop off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of requests left:  339513\n",
      "\n",
      "Percentage of non-corrupted data:  94.19 %\n"
     ]
    }
   ],
   "source": [
    "clean_data = clean_data_do\n",
    "print(\"Number of requests left: \", len(clean_data))\n",
    "print()\n",
    "print(\"Percentage of non-corrupted data: \", round(len(clean_data)/len(data)*100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>drop_off</th>\n",
       "      <th>number_of_pax</th>\n",
       "      <th>pick_up</th>\n",
       "      <th>post_date</th>\n",
       "      <th>post_time</th>\n",
       "      <th>raw_message</th>\n",
       "      <th>request_date</th>\n",
       "      <th>request_date_normalised</th>\n",
       "      <th>request_time</th>\n",
       "      <th>request_time_normalised</th>\n",
       "      <th>user</th>\n",
       "      <th>user_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>tuesday</td>\n",
       "      <td>bedok reservoir</td>\n",
       "      <td>nil</td>\n",
       "      <td>tuas area</td>\n",
       "      <td>26.02.2019</td>\n",
       "      <td>14:55:47</td>\n",
       "      <td>driver looking for hitchers&lt;br/&gt;pick up: tuas ...</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>18:15</td>\n",
       "      <td>18:00</td>\n",
       "      <td>xoxoxo</td>\n",
       "      <td>driver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>tuesday</td>\n",
       "      <td>off - ntu</td>\n",
       "      <td>nil</td>\n",
       "      <td>up - mountbatten mrt</td>\n",
       "      <td>26.02.2019</td>\n",
       "      <td>15:00:23</td>\n",
       "      <td>hitcher looking for drivers&lt;br/&gt;pick up - moun...</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>17:00</td>\n",
       "      <td>17:00</td>\n",
       "      <td>Amanda</td>\n",
       "      <td>hitcher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>tuesday</td>\n",
       "      <td>north-east</td>\n",
       "      <td>nil</td>\n",
       "      <td>bedok/tamp/pasir ris/eunos</td>\n",
       "      <td>26.02.2019</td>\n",
       "      <td>15:39:19</td>\n",
       "      <td>driver looking for hitchers&lt;br/&gt;pick up: bedok...</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>16:00</td>\n",
       "      <td>16:00</td>\n",
       "      <td>J</td>\n",
       "      <td>driver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>tuesday</td>\n",
       "      <td>north-east or east</td>\n",
       "      <td>nil</td>\n",
       "      <td>jurong</td>\n",
       "      <td>26.02.2019</td>\n",
       "      <td>18:12:47</td>\n",
       "      <td>driver looking for hitchers&lt;br/&gt;pick up: juron...</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>18:12</td>\n",
       "      <td>18:00</td>\n",
       "      <td>Colonel Ronald Silver</td>\n",
       "      <td>driver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>tuesday</td>\n",
       "      <td>suss</td>\n",
       "      <td>nil</td>\n",
       "      <td>jurong west</td>\n",
       "      <td>26.02.2019</td>\n",
       "      <td>23:50:17</td>\n",
       "      <td>hitcher looking for drivers &lt;br/&gt;pick up: juro...</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>07:30</td>\n",
       "      <td>07:30</td>\n",
       "      <td>a. Lee</td>\n",
       "      <td>hitcher</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       day            drop_off number_of_pax                     pick_up  \\\n",
       "1  tuesday     bedok reservoir           nil                   tuas area   \n",
       "2  tuesday           off - ntu           nil        up - mountbatten mrt   \n",
       "3  tuesday          north-east           nil  bedok/tamp/pasir ris/eunos   \n",
       "4  tuesday  north-east or east           nil                      jurong   \n",
       "7  tuesday                suss           nil                 jurong west   \n",
       "\n",
       "    post_date post_time                                        raw_message  \\\n",
       "1  26.02.2019  14:55:47  driver looking for hitchers<br/>pick up: tuas ...   \n",
       "2  26.02.2019  15:00:23  hitcher looking for drivers<br/>pick up - moun...   \n",
       "3  26.02.2019  15:39:19  driver looking for hitchers<br/>pick up: bedok...   \n",
       "4  26.02.2019  18:12:47  driver looking for hitchers<br/>pick up: juron...   \n",
       "7  26.02.2019  23:50:17  hitcher looking for drivers <br/>pick up: juro...   \n",
       "\n",
       "  request_date request_date_normalised request_time request_time_normalised  \\\n",
       "1   2019-02-26              2019-02-26        18:15                   18:00   \n",
       "2   2019-02-26              2019-02-26        17:00                   17:00   \n",
       "3   2019-02-26              2019-02-26        16:00                   16:00   \n",
       "4   2019-02-26              2019-02-26        18:12                   18:00   \n",
       "7   2019-02-26              2019-02-26        07:30                   07:30   \n",
       "\n",
       "                    user user_type  \n",
       "1                 xoxoxo    driver  \n",
       "2                 Amanda   hitcher  \n",
       "3                      J    driver  \n",
       "4  Colonel Ronald Silver    driver  \n",
       "7                 a. Lee   hitcher  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalise Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/339513 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 11387/339513 [00:00<00:02, 113861.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 22652/339513 [00:00<00:02, 113494.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 33869/339513 [00:00<00:02, 113090.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 44919/339513 [00:00<00:02, 112300.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 55989/339513 [00:00<00:02, 111812.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 67277/339513 [00:00<00:02, 112128.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 78279/339513 [00:00<00:02, 111485.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 89336/339513 [00:00<00:02, 111208.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 100476/339513 [00:00<00:02, 111264.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 111144/339513 [00:01<00:02, 106871.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 121548/339513 [00:01<00:02, 101685.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 132324/339513 [00:01<00:02, 103433.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 142757/339513 [00:01<00:01, 103700.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 153838/339513 [00:01<00:01, 105734.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 164973/339513 [00:01<00:01, 107358.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 176014/339513 [00:01<00:01, 108254.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 186943/339513 [00:01<00:01, 108562.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 198070/339513 [00:01<00:01, 109359.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 209002/339513 [00:01<00:01, 105399.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 219570/339513 [00:02<00:01, 102212.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 230777/339513 [00:02<00:01, 104982.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████▏  | 241935/339513 [00:02<00:00, 106876.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 253150/339513 [00:02<00:00, 108405.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 264429/339513 [00:02<00:00, 109682.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 275446/339513 [00:02<00:00, 109826.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 286554/339513 [00:02<00:00, 110198.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 297588/339513 [00:02<00:00, 109879.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 308586/339513 [00:02<00:00, 99312.92it/s] \u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 319597/339513 [00:02<00:00, 102322.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 339513/339513 [00:03<00:00, 105936.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 0/339513 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 11421/339513 [00:00<00:02, 114208.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 19182/339513 [00:00<00:03, 100052.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 30065/339513 [00:00<00:03, 102529.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 39143/339513 [00:00<00:03, 98696.40it/s] \u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 50274/339513 [00:00<00:02, 102168.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 61548/339513 [00:00<00:02, 105124.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██▏       | 72704/339513 [00:00<00:02, 106974.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 84090/339513 [00:00<00:02, 108948.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 95601/339513 [00:00<00:02, 110725.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 107049/339513 [00:01<00:02, 111825.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 118546/339513 [00:01<00:01, 112749.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 129982/339513 [00:01<00:01, 113227.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 141502/339513 [00:01<00:01, 113809.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 152791/339513 [00:01<00:01, 113530.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 164179/339513 [00:01<00:01, 113634.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 175498/339513 [00:01<00:01, 113211.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 186789/339513 [00:01<00:01, 113048.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 198073/339513 [00:01<00:01, 112850.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 209401/339513 [00:01<00:01, 112976.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 220953/339513 [00:02<00:01, 113727.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 232320/339513 [00:02<00:00, 113540.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 243798/339513 [00:02<00:00, 113909.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 255187/339513 [00:02<00:00, 111100.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 266311/339513 [00:02<00:00, 104273.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 276834/339513 [00:02<00:00, 102625.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▍ | 287962/339513 [00:02<00:00, 105075.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 299082/339513 [00:02<00:00, 106839.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 310700/339513 [00:02<00:00, 109476.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▍| 322081/339513 [00:02<00:00, 110740.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 339513/339513 [00:03<00:00, 109761.26it/s]\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "# Clean up pick_up and drop_off\n",
    "def clean_location(loc):\n",
    "    # Split multiple nearby locations to use first\n",
    "    if '/' in loc:\n",
    "        loc = loc.split('/')[0].strip()\n",
    "    # Replace short forms\n",
    "    clean = re.sub(r'\\,', ' ', loc)\n",
    "    clean = re.sub(r'  ', ' ', clean)\n",
    "    clean = re.sub(r'\\bamk\\b', 'ang mo kio', clean)\n",
    "    clean = re.sub(r'\\bcck\\b', 'choa chu kang', clean)\n",
    "    clean = re.sub(r'\\btpy\\b', 'toa payoh', clean)\n",
    "    clean = re.sub(r'\\byck\\b', 'yio chu kang', clean)\n",
    "    clean = re.sub(r'^vivo$', 'vivo city', clean)\n",
    "    clean = re.sub(r'\\btamp\\b', 'tampines', clean)\n",
    "    clean = re.sub(r'\\bseng kang\\b', 'sengkang', clean)\n",
    "    clean = re.sub(r'\\bcq\\b', 'clarke quay', clean)\n",
    "    clean = re.sub(r'\\bwlds\\b', 'woodlands', clean)\n",
    "    clean = re.sub(r'^\\bwoodland\\b$', 'woodlands', clean)\n",
    "    clean = re.sub(r'^\\bsim\\b$', 'singapore institute of management', clean)\n",
    "    return clean\n",
    "\n",
    "pick_up = clean_data['pick_up'].tolist()\n",
    "drop_off = clean_data['drop_off'].to_list()\n",
    "\n",
    "pick_up_clean = []\n",
    "drop_off_clean = []\n",
    "\n",
    "for pu in tqdm(pick_up):\n",
    "    pick_up_clean.append(clean_location(str(pu)))\n",
    "    \n",
    "for do in tqdm(drop_off):\n",
    "    drop_off_clean.append(clean_location(str(do)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('woodlands', 9845), ('yishun', 8216), ('sengkang', 7738), ('tampines', 7596), ('punggol', 6152), ('hougang', 5914), ('choa chu kang', 5632), ('ang mo kio', 5393), ('pasir ris', 5341), ('jurong west', 4126), ('bedok', 3910), ('jurong', 3622), ('sembawang', 3254), ('bukit batok', 3189), ('bukit panjang', 2976), ('clarke quay', 2097), ('town', 2018), ('toa payoh', 1892), ('serangoon', 1753), ('clementi', 1686)]\n",
      "\n",
      "[('anywhere', 9954), ('woodlands', 9022), ('yishun', 7782), ('tampines', 7192), ('sengkang', 6964), ('hougang', 5903), ('punggol', 5872), ('choa chu kang', 5457), ('ang mo kio', 5163), ('pasir ris', 4822), ('jurong west', 3888), ('jurong', 3701), ('bedok', 3662), ('bukit panjang', 3015), ('town', 2919), ('sembawang', 2870), ('bukit batok', 2806), ('clementi', 1868), ('toa payoh', 1800), ('serangoon', 1693)]\n"
     ]
    }
   ],
   "source": [
    "print(Counter(pick_up_clean).most_common(20))\n",
    "print()\n",
    "print(Counter(drop_off_clean).most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Org:  wlds 731628\n",
      "Clean:  woodlands 731628\n",
      "\n",
      "Org:  star vista\n",
      "Clean:  star vista\n",
      "\n",
      "Org:  jurong\n",
      "Clean:  jurong\n",
      "\n",
      "Org:  760236\n",
      "Clean:  760236\n",
      "\n",
      "Org:  jurong east/bukit batok\n",
      "Clean:  jurong east\n",
      "\n",
      "Org:  vivo\n",
      "Clean:  vivo city\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if values change\n",
    "for i in range(5004,5010):\n",
    "    print(\"Org: \", pick_up[i])\n",
    "    print(\"Clean: \", pick_up_clean[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>drop_off</th>\n",
       "      <th>number_of_pax</th>\n",
       "      <th>pick_up</th>\n",
       "      <th>post_date</th>\n",
       "      <th>post_time</th>\n",
       "      <th>raw_message</th>\n",
       "      <th>request_date</th>\n",
       "      <th>request_date_normalised</th>\n",
       "      <th>request_time</th>\n",
       "      <th>request_time_normalised</th>\n",
       "      <th>user</th>\n",
       "      <th>user_type</th>\n",
       "      <th>pick_up_clean</th>\n",
       "      <th>drop_off_clean</th>\n",
       "      <th>pick_up_geo</th>\n",
       "      <th>drop_off_geo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>tuesday</td>\n",
       "      <td>bedok reservoir</td>\n",
       "      <td>nil</td>\n",
       "      <td>tuas area</td>\n",
       "      <td>26.02.2019</td>\n",
       "      <td>14:55:47</td>\n",
       "      <td>driver looking for hitchers&lt;br/&gt;pick up: tuas ...</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>18:15</td>\n",
       "      <td>18:00</td>\n",
       "      <td>xoxoxo</td>\n",
       "      <td>driver</td>\n",
       "      <td>tuas area</td>\n",
       "      <td>bedok reservoir</td>\n",
       "      <td>nil</td>\n",
       "      <td>nil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>tuesday</td>\n",
       "      <td>off - ntu</td>\n",
       "      <td>nil</td>\n",
       "      <td>up - mountbatten mrt</td>\n",
       "      <td>26.02.2019</td>\n",
       "      <td>15:00:23</td>\n",
       "      <td>hitcher looking for drivers&lt;br/&gt;pick up - moun...</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>17:00</td>\n",
       "      <td>17:00</td>\n",
       "      <td>Amanda</td>\n",
       "      <td>hitcher</td>\n",
       "      <td>up - mountbatten mrt</td>\n",
       "      <td>off - ntu</td>\n",
       "      <td>nil</td>\n",
       "      <td>nil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>tuesday</td>\n",
       "      <td>north-east</td>\n",
       "      <td>nil</td>\n",
       "      <td>bedok/tamp/pasir ris/eunos</td>\n",
       "      <td>26.02.2019</td>\n",
       "      <td>15:39:19</td>\n",
       "      <td>driver looking for hitchers&lt;br/&gt;pick up: bedok...</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>16:00</td>\n",
       "      <td>16:00</td>\n",
       "      <td>J</td>\n",
       "      <td>driver</td>\n",
       "      <td>bedok</td>\n",
       "      <td>north-east</td>\n",
       "      <td>nil</td>\n",
       "      <td>nil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>tuesday</td>\n",
       "      <td>north-east or east</td>\n",
       "      <td>nil</td>\n",
       "      <td>jurong</td>\n",
       "      <td>26.02.2019</td>\n",
       "      <td>18:12:47</td>\n",
       "      <td>driver looking for hitchers&lt;br/&gt;pick up: juron...</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>18:12</td>\n",
       "      <td>18:00</td>\n",
       "      <td>Colonel Ronald Silver</td>\n",
       "      <td>driver</td>\n",
       "      <td>jurong</td>\n",
       "      <td>north-east or east</td>\n",
       "      <td>nil</td>\n",
       "      <td>nil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>tuesday</td>\n",
       "      <td>suss</td>\n",
       "      <td>nil</td>\n",
       "      <td>jurong west</td>\n",
       "      <td>26.02.2019</td>\n",
       "      <td>23:50:17</td>\n",
       "      <td>hitcher looking for drivers &lt;br/&gt;pick up: juro...</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>07:30</td>\n",
       "      <td>07:30</td>\n",
       "      <td>a. Lee</td>\n",
       "      <td>hitcher</td>\n",
       "      <td>jurong west</td>\n",
       "      <td>suss</td>\n",
       "      <td>nil</td>\n",
       "      <td>nil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       day            drop_off number_of_pax                     pick_up  \\\n",
       "1  tuesday     bedok reservoir           nil                   tuas area   \n",
       "2  tuesday           off - ntu           nil        up - mountbatten mrt   \n",
       "3  tuesday          north-east           nil  bedok/tamp/pasir ris/eunos   \n",
       "4  tuesday  north-east or east           nil                      jurong   \n",
       "7  tuesday                suss           nil                 jurong west   \n",
       "\n",
       "    post_date post_time                                        raw_message  \\\n",
       "1  26.02.2019  14:55:47  driver looking for hitchers<br/>pick up: tuas ...   \n",
       "2  26.02.2019  15:00:23  hitcher looking for drivers<br/>pick up - moun...   \n",
       "3  26.02.2019  15:39:19  driver looking for hitchers<br/>pick up: bedok...   \n",
       "4  26.02.2019  18:12:47  driver looking for hitchers<br/>pick up: juron...   \n",
       "7  26.02.2019  23:50:17  hitcher looking for drivers <br/>pick up: juro...   \n",
       "\n",
       "  request_date request_date_normalised request_time request_time_normalised  \\\n",
       "1   2019-02-26              2019-02-26        18:15                   18:00   \n",
       "2   2019-02-26              2019-02-26        17:00                   17:00   \n",
       "3   2019-02-26              2019-02-26        16:00                   16:00   \n",
       "4   2019-02-26              2019-02-26        18:12                   18:00   \n",
       "7   2019-02-26              2019-02-26        07:30                   07:30   \n",
       "\n",
       "                    user user_type         pick_up_clean      drop_off_clean  \\\n",
       "1                 xoxoxo    driver             tuas area     bedok reservoir   \n",
       "2                 Amanda   hitcher  up - mountbatten mrt           off - ntu   \n",
       "3                      J    driver                 bedok          north-east   \n",
       "4  Colonel Ronald Silver    driver                jurong  north-east or east   \n",
       "7                 a. Lee   hitcher           jurong west                suss   \n",
       "\n",
       "  pick_up_geo drop_off_geo  \n",
       "1         nil          nil  \n",
       "2         nil          nil  \n",
       "3         nil          nil  \n",
       "4         nil          nil  \n",
       "7         nil          nil  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add columns to dataframe\n",
    "data_normalised = clean_data.assign(pick_up_clean=pick_up_clean,\n",
    "                                    drop_off_clean=drop_off_clean,\n",
    "                                    pick_up_geo=\"nil\",\n",
    "                                    drop_off_geo=\"nil\")\n",
    "data_normalised.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from fake_useragent import UserAgent\n",
    "#ua = UserAgent()\n",
    "#HEADER = {'User-Agent': ua.random}\n",
    "HEADERS_LIST = [\n",
    "    'Mozilla/5.0 (Windows; U; Windows NT 6.1; x64; fr; rv:1.9.2.13) Gecko/20101203 Firebird/3.6.13',\n",
    "    'Mozilla/5.0 (compatible, MSIE 11, Windows NT 6.3; Trident/7.0; rv:11.0) like Gecko',\n",
    "    'Mozilla/5.0 (Windows; U; Windows NT 6.1; rv:2.2) Gecko/20110201',\n",
    "    'Opera/9.80 (X11; Linux i686; Ubuntu/14.10) Presto/2.12.388 Version/12.16',\n",
    "    'Mozilla/5.0 (Windows NT 5.2; RW; rv:7.0a1) Gecko/20091211 SeaMonkey/9.23a1pre'\n",
    "]\n",
    "\n",
    "PROXY_URL = 'https://free-proxy-list.net/'\n",
    "\n",
    "def get_proxies():\n",
    "    response = requests.get(PROXY_URL)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    table = soup.find('table',id='proxylisttable')\n",
    "    list_tr = table.find_all('tr')\n",
    "    list_td = [elem.find_all('td') for elem in list_tr]\n",
    "    list_td = list(filter(None, list_td))\n",
    "    list_ip = [elem[0].text for elem in list_td]\n",
    "    list_ports = [elem[1].text for elem in list_td]\n",
    "    list_proxies = [':'.join(elem) for elem in list(zip(list_ip, list_ports))]\n",
    "    return list_proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get lat-long of location pick_up_clean and drop_off_clean\n",
    "\n",
    "random_get_proxy = []\n",
    "for i in range(999):\n",
    "    random_get_proxy.append(False)\n",
    "random_get_proxy.append(True)\n",
    "\n",
    "proxies = get_proxies()\n",
    "proxy_pool = cycle(proxies)\n",
    "\n",
    "def get_address(row_index):\n",
    "    \n",
    "    #-----PARAMETERS------\n",
    "    if random.choice(random_get_proxy):\n",
    "        proxies = get_proxies()\n",
    "        proxy_pool = cycle(proxies)\n",
    "        print(\"Reset proxies\")\n",
    "    HEADER = {'User-Agent': random.choice(HEADERS_LIST)}\n",
    "    proxy = next(proxy_pool)\n",
    "    #---------------------\n",
    "    \n",
    "    pick_up_geo = \"nil\"\n",
    "    drop_off_geo = \"nil\"\n",
    "    \n",
    "    if bool(re.search(r'\\d{6}', data_normalised.iloc[row_index]['pick_up_clean'])):\n",
    "        pu_location = re.search(r'\\d{6}', data_normalised.iloc[row_index]['pick_up_clean']).group()\n",
    "    else:\n",
    "        pu_location = data_normalised.iloc[row_index]['pick_up_clean']\n",
    "    onemap_url = \"https://developers.onemap.sg/commonapi/search\"\n",
    "    onemap_params = {'searchVal' : pu_location, 'returnGeom' : \"Y\", 'getAddrDetails' : \"Y\"}\n",
    "    r = requests.get(url = onemap_url, params = onemap_params, headers=HEADER, proxies={\"http\": proxy}, timeout=60)\n",
    "    data = r.json()\n",
    "    try:\n",
    "        lat = data['results'][0]['LATITUDE']\n",
    "        long = data['results'][0]['LONGTITUDE']\n",
    "        lat_long = lat+\",\"+long\n",
    "        pick_up_geo = lat_long\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if bool(re.search(r'\\d{6}', data_normalised.iloc[row_index]['drop_off_clean'])):\n",
    "        do_location = re.search(r'\\d{6}', data_normalised.iloc[row_index]['drop_off_clean']).group()\n",
    "    else:\n",
    "        do_location = data_normalised.iloc[row_index]['drop_off_clean']\n",
    "    onemap_params = {'searchVal' : do_location, 'returnGeom' : \"Y\", 'getAddrDetails' : \"Y\"}\n",
    "    r = requests.get(url = onemap_url, params = onemap_params, headers=HEADER, proxies={\"http\": proxy}, timeout=60)\n",
    "    data = r.json()\n",
    "    try:\n",
    "        lat = data['results'][0]['LATITUDE']\n",
    "        long = data['results'][0]['LONGTITUDE']\n",
    "        lat_long = lat+\",\"+long\n",
    "        drop_off_geo = lat_long\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return pd.DataFrame([[row_index, pu_location, pick_up_geo, do_location, drop_off_geo]], columns=['index', 'pick_up_loc', 'pick_up_geo', 'drop_off_loc', 'drop_off_geo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:  0:02:07.866620\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "with Pool(15) as p:\n",
    "    result = p.map(get_address, range(1000))\n",
    "print(\"time: \", datetime.now()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>pick_up_loc</th>\n",
       "      <th>pick_up_geo</th>\n",
       "      <th>drop_off_loc</th>\n",
       "      <th>drop_off_geo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>tuas area</td>\n",
       "      <td>nil</td>\n",
       "      <td>bedok reservoir</td>\n",
       "      <td>1.34231030001047,103.925857758506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>up - mountbatten mrt</td>\n",
       "      <td>nil</td>\n",
       "      <td>off - ntu</td>\n",
       "      <td>nil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>bedok</td>\n",
       "      <td>1.32368201682055,103.947789319297</td>\n",
       "      <td>north-east</td>\n",
       "      <td>nil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>jurong</td>\n",
       "      <td>1.34390440884759,103.766254087753</td>\n",
       "      <td>north-east or east</td>\n",
       "      <td>nil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>jurong west</td>\n",
       "      <td>1.34160326621595,103.70808518963301</td>\n",
       "      <td>suss</td>\n",
       "      <td>1.3136407681546398,103.790065521402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>995</td>\n",
       "      <td>hougang</td>\n",
       "      <td>1.3799438359273999,103.887465509279</td>\n",
       "      <td>bedok</td>\n",
       "      <td>1.32368201682055,103.947789319297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>996</td>\n",
       "      <td>one pickering st</td>\n",
       "      <td>1.2861012420485,103.84549974800699</td>\n",
       "      <td>anywhere</td>\n",
       "      <td>nil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>997</td>\n",
       "      <td>cgh a&amp;amp;e</td>\n",
       "      <td>1.27911290969895,103.835013662224</td>\n",
       "      <td>tekka market</td>\n",
       "      <td>1.30617705325624,103.85061131325001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>998</td>\n",
       "      <td>katong 112</td>\n",
       "      <td>1.30522306203046,103.90504392893801</td>\n",
       "      <td>white sand primary(pasir ris)</td>\n",
       "      <td>nil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>jurong point</td>\n",
       "      <td>1.3394520043632099,103.706685012926</td>\n",
       "      <td>woodlands ave 4</td>\n",
       "      <td>1.44291482766827,103.79368372996599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index           pick_up_loc                          pick_up_geo  \\\n",
       "0       0             tuas area                                  nil   \n",
       "0       1  up - mountbatten mrt                                  nil   \n",
       "0       2                 bedok    1.32368201682055,103.947789319297   \n",
       "0       3                jurong    1.34390440884759,103.766254087753   \n",
       "0       4           jurong west  1.34160326621595,103.70808518963301   \n",
       "..    ...                   ...                                  ...   \n",
       "0     995               hougang  1.3799438359273999,103.887465509279   \n",
       "0     996      one pickering st   1.2861012420485,103.84549974800699   \n",
       "0     997           cgh a&amp;e    1.27911290969895,103.835013662224   \n",
       "0     998            katong 112  1.30522306203046,103.90504392893801   \n",
       "0     999          jurong point  1.3394520043632099,103.706685012926   \n",
       "\n",
       "                     drop_off_loc                         drop_off_geo  \n",
       "0                 bedok reservoir    1.34231030001047,103.925857758506  \n",
       "0                       off - ntu                                  nil  \n",
       "0                      north-east                                  nil  \n",
       "0              north-east or east                                  nil  \n",
       "0                            suss  1.3136407681546398,103.790065521402  \n",
       "..                            ...                                  ...  \n",
       "0                           bedok    1.32368201682055,103.947789319297  \n",
       "0                        anywhere                                  nil  \n",
       "0                    tekka market  1.30617705325624,103.85061131325001  \n",
       "0   white sand primary(pasir ris)                                  nil  \n",
       "0                 woodlands ave 4  1.44291482766827,103.79368372996599  \n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data.to_csv(\"./data/sg_hitch_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
